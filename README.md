The project aimed to develop a robust translation system for Indian Sign Language (ISL) using a combination of Convolutional Neural Network (CNN) and Artificial Neural Network (ANN) models. The goal was to bridge the communication gap between individuals who use ISL and those who do not. The dataset comprised 50 different Indian sign languages to ensure comprehensive coverage.

The CNN model was employed for feature extraction from sign language images, leveraging its ability to recognize spatial patterns effectively. These features were then passed on to the ANN model, which was responsible for translating the extracted features into corresponding textual or spoken representations.
